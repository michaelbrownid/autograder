{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFilter\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import pandas as pd\n",
    "import processing as proc\n",
    "from math import ceil\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "keras = tf.keras\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE ## tf.data transformation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folders = os.popen(\"ls ../number_sets/numbers-master\").read().split('\\n')[:-1]\n",
    "for i,img in enumerate(folders):\n",
    "    folders[i]='../number_sets/numbers-master/'+img\n",
    "folders=folders[:29]\n",
    "# folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm new_traindata_numbermaster__FINALPASS.txt     Uncomment to overwrite file\n",
    "arrays = []\n",
    "labels = []\n",
    "filenames = []\n",
    "for folder in folders:\n",
    "    for dig in [0,2,3,4,5,6,7,8,9]:\n",
    "        direct = folder+'/'+str(dig)+'/'\n",
    "        cmd = \"ls \" +direct\n",
    "        imgs = os.popen(cmd).read().split('\\n')[:-1]\n",
    "        for i,img in enumerate(imgs):\n",
    "            file = direct+img\n",
    "            filenames.append(file)\n",
    "            with open('new_traindata_numbermaster__FINALPASS.txt','a') as writeFile:\n",
    "                answer=dig\n",
    "                binary_arr,label_arr, segments,orig = proc.label_segments(file,'',photo=False,marker=False)\n",
    "                found = binary_arr==0\n",
    "                try:\n",
    "                    x,y = np.where(found)\n",
    "                    xmin,xmax,ymin,ymax = np.min(x),np.max(x),np.min(y),np.max(y)\n",
    "                    xlen,ylen = found[xmin:xmax,ymin:ymax].shape\n",
    "                    diff = np.abs(ylen-xlen)\n",
    "                    change = ceil(diff/2)\n",
    "                    if diff!=0:\n",
    "                        if ylen>xlen:\n",
    "                            xmin-=change\n",
    "                            xmax+=change\n",
    "\n",
    "                        else:\n",
    "                            ymin-=change\n",
    "                            ymax+=change\n",
    "\n",
    "                        xlen,ylen = xmax-xmin,ymax-ymin\n",
    "                        diff=np.abs(ylen-xlen)\n",
    "                        if xlen>ylen: ymax+=diff\n",
    "                        elif ylen>xlen: xmax+=diff\n",
    "                    digit = 1-binary_arr[xmin:xmax,ymin:ymax]\n",
    "                    digit = np.pad(digit,int(len(digit)*.2),mode= 'constant', constant_values=(0,0))                  \n",
    "                    im = Image.fromarray(np.array(digit)*255.0).convert(\"RGB\")\n",
    "                    im.save('000.png')\n",
    "                    del im\n",
    "                    del digit\n",
    "                    \n",
    "                except:  #Takes care of tuple issue\n",
    "                    src = cv2.imread(file, cv2.IMREAD_GRAYSCALE) \n",
    "                    image_file = 255-cv2.GaussianBlur(src,(5,5),cv2.BORDER_DEFAULT)\n",
    "                    del src\n",
    "                    yooo = Image.fromarray(image_file)\n",
    "                    del image_file\n",
    "                    yooo.save('000.png')   \n",
    "                img = cv2.resize(cv2.imread('000.png',cv2.IMREAD_GRAYSCALE),(28,28),interpolation=cv2.INTER_CUBIC)\n",
    "                arr = list(img.flatten())\n",
    "                arr.append(int(answer))\n",
    "                writeFile.write(str(arr)+';')\n",
    "                del arr\n",
    "                arrays.append(img)\n",
    "                labels.append(int(answer))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays = []\n",
    "# labels = []\n",
    "# with open('new_traindata.txt','a') as writeFile:\n",
    "#     for digit in imgs:\n",
    "# #         answer = digit[-5:-4]\n",
    "#         answer=0\n",
    "#         img = cv2.resize(cv2.imread(digit,cv2.IMREAD_GRAYSCALE),(28,28),interpolation=cv2.INTER_CUBIC)\n",
    "# #         plt.imshow(img)\n",
    "#         arr = list(img.flatten())\n",
    "#         arr.append(int(answer))\n",
    "#         writeFile.write(str(arr)+';')\n",
    "#         arrays.append(img)\n",
    "#         labels.append(int(answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_tr,y_tr),(X_ts,y_ts) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15306, 28, 28)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(arrays).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb0cf6c9588>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arrays[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_5epochs_20191028.h5  mnist_hasyv2_20epochs_201910291572394063.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls saved_models\n",
    "models = os.popen(\"ls saved_models\").read().split('\\n')[:-1]\n",
    "tf_model = keras.models.load_model('saved_models/'+models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>../number_sets/numbers-master/0001_CH4M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>../number_sets/numbers-master/0001_CH4M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>../number_sets/numbers-master/0001_CH4M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>../number_sets/numbers-master/0001_CH4M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>../number_sets/numbers-master/0001_CH4M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2995</td>\n",
       "      <td>../number_sets/numbers-master/0007_CH3M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>../number_sets/numbers-master/0007_CH3M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>../number_sets/numbers-master/0007_CH3M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2998</td>\n",
       "      <td>../number_sets/numbers-master/0007_CH3M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>../number_sets/numbers-master/0007_CH3M/0/numb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               filename  label  \\\n",
       "0     ../number_sets/numbers-master/0001_CH4M/0/numb...      0   \n",
       "1     ../number_sets/numbers-master/0001_CH4M/0/numb...      0   \n",
       "2     ../number_sets/numbers-master/0001_CH4M/0/numb...      0   \n",
       "3     ../number_sets/numbers-master/0001_CH4M/0/numb...      0   \n",
       "4     ../number_sets/numbers-master/0001_CH4M/0/numb...      0   \n",
       "...                                                 ...    ...   \n",
       "2995  ../number_sets/numbers-master/0007_CH3M/0/numb...      0   \n",
       "2996  ../number_sets/numbers-master/0007_CH3M/0/numb...      0   \n",
       "2997  ../number_sets/numbers-master/0007_CH3M/0/numb...      0   \n",
       "2998  ../number_sets/numbers-master/0007_CH3M/0/numb...      0   \n",
       "2999  ../number_sets/numbers-master/0007_CH3M/0/numb...      0   \n",
       "\n",
       "                                                  array  \n",
       "0     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "1     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "3     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "4     [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "...                                                 ...  \n",
       "2995  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2996  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2997  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2998  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "2999  [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newset = pd.DataFrame(filenames[:3000])\n",
    "newset.columns = ['filename']\n",
    "newset['label']=labels[:3000]\n",
    "newset['array']=arrays[:3000]\n",
    "newset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "300\n",
      "600\n",
      "900\n",
      "1200\n",
      "1500\n",
      "1800\n",
      "2100\n",
      "2400\n",
      "2700\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for LOC in range(len(newset)):\n",
    "    predictions.append(np.argmax(tf_model.predict(newset.array.iloc[LOC].astype(float).flatten().reshape((1, 28, 28, 1)))))\n",
    "    if LOC%300==0:\n",
    "        print(LOC)\n",
    "newset['predict']=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>predict</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2997</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  predict  score\n",
       "0         0        0      1\n",
       "1         0        0      1\n",
       "2         0        0      1\n",
       "3         0        0      1\n",
       "4         0        0      1\n",
       "...     ...      ...    ...\n",
       "2995      0        0      1\n",
       "2996      0        0      1\n",
       "2997      0        6      0\n",
       "2998      0        0      1\n",
       "2999      0        0      1\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newset['score']=(newset.label==newset.predict)*1\n",
    "newset[['label','predict','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3000.000000\n",
       "mean        0.844667\n",
       "std         0.362283\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newset.score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_arr,label_arr, segments,orig = proc.label_segments(newset.filename.iloc[1157],'',photo=False,marker=False)\n",
    "# plt.imshow(binary_arr)\n",
    "# found = binary_arr==0\n",
    "# x,y = np.where(found)\n",
    "# xmin,xmax,ymin,ymax = np.min(x),np.max(x),np.min(y),np.max(y)\n",
    "# xlen,ylen = found[xmin:xmax,ymin:ymax].shape\n",
    "# diff = np.abs(ylen-xlen)\n",
    "# change = ceil(diff/2)\n",
    "# if diff!=0:\n",
    "#     if ylen>xlen:\n",
    "#         xmin-=change\n",
    "#         xmax+=change\n",
    "\n",
    "#     else:\n",
    "#         ymin-=change\n",
    "#         ymax+=change\n",
    "\n",
    "#     xlen,ylen = xmax-xmin,ymax-ymin\n",
    "#     diff=np.abs(ylen-xlen)\n",
    "#     if xlen>ylen: ymax+=diff\n",
    "#     elif ylen>xlen: xmax+=diff\n",
    "# digit = 1-binary_arr[xmin:xmax,ymin:ymax]\n",
    "# digit = np.pad(digit,int(len(digit)*.2),mode= 'constant', constant_values=(0,0))        \n",
    "# plt.imshow(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(tf_model.predict(img.astype(float).flatten().reshape((1, 28, 28, 1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../number_sets/numbers-master/0001_CH4M/2/number-440.png'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newset.iloc[100].filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HASYv2 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nina/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "file = 'HASYv2/hasy-data-labels.csv'\n",
    "df = pd.read_csv(file)\n",
    "digits = df[(df['symbol_id']<=79) & (df['symbol_id']>=70)]\n",
    "# digits 0-9\n",
    "def make_pixel_array(df):\n",
    "    im = Image.open('HASYv2/'+df['path'],'r').convert('L')\n",
    "    return np.asarray(im)  ##255-val inverts colors\n",
    "digits['pixels']=digits.apply(make_pixel_array,axis=1)\n",
    "nrows = 28\n",
    "ncolumns = 28\n",
    "channels = 1\n",
    "def read_process_images(img_list,y,invert=False):\n",
    "    img_list,y = shuffle(img_list,y)\n",
    "    X=[]\n",
    "    for path in img_list:\n",
    "        image = 'HASYv2/' + path       ##can do color .IMREAD_COLOR\n",
    "        X.append(cv2.resize(cv2.imread(image,cv2.IMREAD_GRAYSCALE),(nrows,ncolumns),interpolation=cv2.INTER_CUBIC))\n",
    "    if invert==True:\n",
    "        return 255-np.array(X),np.array(y)\n",
    "    return np.array(X),np.array(y)\n",
    "X,y = read_process_images(digits['path'],digits['latex'],invert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOIN HASYv2, MNIST, NEWSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_JOINED = np.concatenate((arrays,X_tr, X,X_ts), axis=0)\n",
    "y_JOINED = np.concatenate((labels,y_tr, y,y_ts), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINALTRAINSET = pd.DataFrame(list(zip(X_JOINED,y_JOINED)))\n",
    "FINALTRAINSET.columns = ['X','y']\n",
    "FINALTRAINSET.to_csv('final_trainset.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sss = StratifiedShuffleSplit(1, train_size=0.8)\n",
    "# sss.get_n_splits(X_JOINED, y_JOINED)\n",
    "# X_train, X_test = sss.split(X_JOINED, y_JOINED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RETRAIN CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_JOINED, y_JOINED,train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = models.Sequential()\n",
    "conv_model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "conv_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "conv_model.add(layers.MaxPooling2D((2, 2)))\n",
    "conv_model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "conv_model.add(layers.Flatten())\n",
    "conv_model.add(layers.Dense(64, activation='relu'))\n",
    "conv_model.add(layers.Dense(10, activation='softmax'))\n",
    "conv_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "x_train = X_train.astype('int32')\n",
    "x_test = X_test.astype('int32')\n",
    "\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "x_train = np.array([x.reshape(28,28,1) for x in x_train])\n",
    "x_test = np.array([x.reshape(28,28,1) for x in x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69060 samples\n",
      "Epoch 1/20\n",
      "69060/69060 [==============================] - 50s 727us/sample - loss: 0.3012 - accuracy: 0.9245\n",
      "Epoch 2/20\n",
      "69060/69060 [==============================] - 45s 648us/sample - loss: 0.1099 - accuracy: 0.9644\n",
      "Epoch 3/20\n",
      "69060/69060 [==============================] - 47s 679us/sample - loss: 0.0954 - accuracy: 0.9683\n",
      "Epoch 4/20\n",
      "69060/69060 [==============================] - 46s 659us/sample - loss: 0.0854 - accuracy: 0.9719\n",
      "Epoch 5/20\n",
      "21312/69060 [========>.....................] - ETA: 31s - loss: 0.0760 - accuracy: 0.9746"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(y_train).astype('int32')\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_test)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y_test = np_utils.to_categorical(y_test).astype('int32')\n",
    "conv_model.fit(x_train, dummy_y_train, batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "saved_model_path = \"./saved_models/mnist_hasyv2_master_20epochs_{}.h5\".format(datetime.now().strftime(\"%Y%m%d%s\")) # _%H%M%S\n",
    "# Save entire model to a HDF5 file\n",
    "conv_model.save(saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(y):\n",
    "    return np.argmax(y)\n",
    "y_pred_prob = conv_model.predict(x_test.astype('float32'))\n",
    "y_pred = np.array([get_prediction(y) for y in y_pred_prob])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(y_pred[y_test == 0], alpha=0.3, bins=20, label=\"0\")\n",
    "ax.hist(y_pred[y_test == 1], alpha=0.3, bins=20, label=\"1\")\n",
    "ax.hist(y_pred[y_test == 2], alpha=0.3, bins=20, label=\"2\")\n",
    "ax.hist(y_pred[y_test == 3], alpha=0.3, bins=20, label=\"3\")\n",
    "ax.hist(y_pred[y_test == 4], alpha=0.3, bins=20, label=\"4\")\n",
    "ax.hist(y_pred[y_test == 5], alpha=0.3, bins=20, label=\"5\")\n",
    "ax.hist(y_pred[y_test == 6], alpha=0.3, bins=20, label=\"6\")\n",
    "ax.hist(y_pred[y_test == 7], alpha=0.3, bins=20, label=\"7\")\n",
    "ax.hist(y_pred[y_test == 8], alpha=0.3, bins=20, label=\"8\")\n",
    "ax.hist(y_pred[y_test == 9], alpha=0.3, bins=20, label=\"9\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = pd.DataFrame(y_test)\n",
    "results.columns = ['actual']\n",
    "results['predict']=y_pred\n",
    "results['match']=(results['actual']==results['predict'])*1\n",
    "results['match'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
